{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq5sNzGGi2Gf"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "iyyToMD1izQ4"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [2]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnn\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnn\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01moptim\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01moptim\u001B[39;00m\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from tqdm.auto import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kPei2V5aGFj"
   },
   "source": [
    "## For Google Colab Users\n",
    "\n",
    "This cell is for mounting your Google Drive to the Colab Notebook. If you are not using Google Colab, you can skip this cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "2d0lQY8oSaJ0"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Input \u001B[1;32mIn [3]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8gvAZZ9Fjv31"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [4]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Check for GPU\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m device \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcpu\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Check for GPU in mac\u001B[39;00m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\u001B[39;00m\n\u001B[0;32m      7\u001B[0m device\n",
      "\u001B[1;31mNameError\u001B[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Check for GPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Check for GPU in mac\n",
    "# device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sc1Ga5_MmtOT"
   },
   "source": [
    "# Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IE19W1MAv_6W"
   },
   "source": [
    "## Transforming Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "eb0rjSZWmnlN"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [5]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m data_transforms \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      2\u001B[0m \n\u001B[1;32m----> 3\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraining\u001B[39m\u001B[38;5;124m'\u001B[39m : \u001B[43mtransforms\u001B[49m\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      4\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mRandomResizedCrop((\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m)),\n\u001B[0;32m      5\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mRandomHorizontalFlip(),\n\u001B[0;32m      6\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mToTensor()\n\u001B[0;32m      7\u001B[0m     ]),\n\u001B[0;32m      8\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTesting\u001B[39m\u001B[38;5;124m'\u001B[39m: transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      9\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mResize((\u001B[38;5;241m224\u001B[39m, \u001B[38;5;241m224\u001B[39m)),\n\u001B[0;32m     10\u001B[0m         transforms\u001B[38;5;241m.\u001B[39mToTensor()\n\u001B[0;32m     11\u001B[0m \n\u001B[0;32m     12\u001B[0m     ])\n\u001B[0;32m     13\u001B[0m }\n",
      "\u001B[1;31mNameError\u001B[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "\n",
    "    'Training' : transforms.Compose([\n",
    "        transforms.RandomResizedCrop((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor()\n",
    "    ]),\n",
    "    'Testing': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor()\n",
    "\n",
    "    ])\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aEQ5zz64wRuM"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "79gT4HqIwh96"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'os' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# directory: where training and testing data are\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m base_path \u001B[38;5;241m=\u001B[39m \u001B[43mos\u001B[49m\u001B[38;5;241m.\u001B[39mgetcwd()\n\u001B[0;32m      3\u001B[0m data_dir \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mpath\u001B[38;5;241m.\u001B[39mjoin(base_path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdataset\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m### START CODE HERE\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \n\u001B[0;32m      7\u001B[0m \u001B[38;5;66;03m# datasets.ImageFolder: (https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;66;03m# image_datasets are dictionary of (type of dataset, dataloader)\u001B[39;00m\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# type of dataset are training and testing\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'os' is not defined"
     ]
    }
   ],
   "source": [
    "# directory: where training and testing data are\n",
    "base_path = os.getcwd()\n",
    "data_dir = os.path.join(base_path, 'dataset')\n",
    "\n",
    "### START CODE HERE\n",
    "\n",
    "# datasets.ImageFolder: (https://pytorch.org/vision/main/generated/torchvision.datasets.ImageFolder.html)\n",
    "# torch.utils.data.DataLoader: (https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader)\n",
    "\n",
    "# image_datasets are dictionary of (type of dataset, dataloader)\n",
    "# type of dataset are training and testing\n",
    "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x), data_transforms[x]) for x in None}\n",
    "\n",
    "# DataLoader helps us for better performance and experience in data loading\n",
    "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32, shuffle=True) for x in None}\n",
    "### END CODE HERE\n",
    "\n",
    "dataset_sizes = {x: len(image_datasets[x]) for x in None}\n",
    "class_names = image_datasets['Training'].classes\n",
    "\n",
    "dataset_sizes, class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GImh9haJ0_CN"
   },
   "source": [
    "## Samples of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iZzAK1l3y1Tk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloaders' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [7]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[0m samples, labels \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(\u001B[38;5;28miter\u001B[39m(\u001B[43mdataloaders\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTesting\u001B[39m\u001B[38;5;124m'\u001B[39m]))\n\u001B[0;32m      2\u001B[0m plt\u001B[38;5;241m.\u001B[39mfigure(figsize\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m17\u001B[39m, \u001B[38;5;241m10\u001B[39m))\n\u001B[0;32m      3\u001B[0m plt\u001B[38;5;241m.\u001B[39maxis(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124moff\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'dataloaders' is not defined"
     ]
    }
   ],
   "source": [
    "samples, labels = next(iter(dataloaders['Testing']))\n",
    "plt.figure(figsize=(17, 10))\n",
    "plt.axis('off')\n",
    "for i in range(32):\n",
    "    plt.subplot(4, 8, i+1)\n",
    "    plt.imshow(samples[i].permute(1, 2, 0))\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P3Q-LEGY1P_T"
   },
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlhrp8mU1mA-"
   },
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "xSBfR1g51oVi"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m# Loading are pretrained model in this task our model is resnet50 (https://www.youtube.com/watch?v=mGMpHyiN5lk)\u001B[39;00m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;66;03m### START CODE HERE\u001B[39;00m\n\u001B[0;32m      3\u001B[0m \n\u001B[0;32m      4\u001B[0m \u001B[38;5;66;03m# Loading pretrained model\u001B[39;00m\n\u001B[1;32m----> 5\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mmodels\u001B[49m\u001B[38;5;241m.\u001B[39mresnet50(pretrained\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m)\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param \u001B[38;5;129;01min\u001B[39;00m model\u001B[38;5;241m.\u001B[39mparameters():\n\u001B[0;32m      7\u001B[0m     param\u001B[38;5;241m.\u001B[39mrequires_grad \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m\n",
      "\u001B[1;31mNameError\u001B[0m: name 'models' is not defined"
     ]
    }
   ],
   "source": [
    "# Loading are pretrained model in this task our model is resnet50 (https://www.youtube.com/watch?v=mGMpHyiN5lk)\n",
    "### START CODE HERE\n",
    "\n",
    "# Loading pretrained model\n",
    "model = models.resnet50(pretrained=None)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "### END CODE HERE\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VGVAHQqE16mN"
   },
   "source": [
    "## Preparing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QIVyMWO111cV"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "# You have to change the (fc) layer of the model to compatible with your data\n",
    "model.fc = nn.Linear(model.fc.in_features, None)\n",
    "\n",
    "### END CODE HERE\n",
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ybTYDJFw3Zvu"
   },
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nK2lRW9M3oqU"
   },
   "source": [
    "## Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lKH6IFcj3sBy"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIN1OsTL32Lu"
   },
   "source": [
    "## Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02TRqi3j3vBa"
   },
   "outputs": [],
   "source": [
    "# you have to change it for better performance\n",
    "optimizer = optim.Adam(model.parameters(), lr=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8Ulk0xEvIJN"
   },
   "source": [
    "## Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5kCVzWjPvMh-"
   },
   "outputs": [],
   "source": [
    "# you can have other thongs like learning rate scheduler and ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_T4qQCAo37ZN"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MaimiD3B4ILt"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "losses = []\n",
    "EPOCH = None\n",
    "\n",
    "# for training part you have to set model to train mode\n",
    "model.train()\n",
    "\n",
    "# loop on epochs\n",
    "for e in tqdm(range(EPOCH)):\n",
    "\n",
    "  # loop on batches\n",
    "  for inputs, labels in dataloaders[None]:\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "\n",
    "    # set the grad to zero\n",
    "    optimizer.None\n",
    "    \n",
    "    # forward part\n",
    "    # hint: using of pytorch max method (https://pytorch.org/docs/stable/generated/torch.max.html)\n",
    "    outputs = model(None)\n",
    "    _, preds = None\n",
    "\n",
    "    #  compute loss\n",
    "    loss = criterion(None, None)\n",
    "    \n",
    "    # backward part\n",
    "    loss.backward()\n",
    "\n",
    "    # update parameters\n",
    "    optimizer.step()\n",
    "\n",
    "  # you have to append loss for each epoch\n",
    "  losses.append(None)\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wked8jWxwvF6"
   },
   "source": [
    "## Plot loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3GfAppV85Bhd"
   },
   "outputs": [],
   "source": [
    "# you have to calculate losses arrayin Train part\n",
    "plt.plot(list(range(len(losses))), losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W9NF0ICIygXC"
   },
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_DtYxBrp8_5X"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "def calc_accuracy(data, model):\n",
    "  corrects = 0\n",
    "\n",
    "  # for testing part you have to set model to eval mode\n",
    "  model.eval()\n",
    "  for inputs, labels in tqdm(dataloaders[data]):\n",
    "      inputs = inputs.to(device)\n",
    "      labels = labels.to(device)\n",
    "      \n",
    "      with torch.no_grad():\n",
    "        outputs = model(None)\n",
    "        _, preds = None\n",
    "        corrects += torch.sum(preds == labels.data)\n",
    "  return corrects.double() / dataset_sizes[data]\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CEczQlhSDH8s"
   },
   "outputs": [],
   "source": [
    "# accuracy of training data\n",
    "calc_accuracy(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FaBRMH8GDK4w"
   },
   "outputs": [],
   "source": [
    "# accuracy of testing data\n",
    "calc_accuracy(None, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dgfDRa6pzjur"
   },
   "source": [
    "# Saving Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "axaIXsCMzhPp"
   },
   "outputs": [],
   "source": [
    "PATH = os.path.join(base_path, 'model.ci')\n",
    "torch.save(model, PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cPZGSYXQ0CkV"
   },
   "source": [
    "# Loading and eval Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5WH_sGX30G-Q"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE\n",
    "\n",
    "model_for_eval = torch.load(PATH)\n",
    "model_for_eval.to(device)\n",
    "\n",
    "### END CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "34pzOFb51ooA"
   },
   "outputs": [],
   "source": [
    "model_for_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PvhXDIv90dln"
   },
   "outputs": [],
   "source": [
    "# accuracy of training data by loadded model\n",
    "calc_accuracy(None, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YX6vykni0eL9"
   },
   "outputs": [],
   "source": [
    "# accuracy of testing data by loadded model\n",
    "calc_accuracy(None, None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}